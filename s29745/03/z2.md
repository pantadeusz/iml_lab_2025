# Wnioski z analizy modeli na danych niezbalansowanych

Na zbiorze silnie niezbalansowanym (189 próbek klasy 0 i 11 klasy 1) model bazowy praktycznie nie wykrywał klasy mniejszościowej – `Recall` wyniósł tylko 0.09 (wykrył 1 z 11 próbek), a wysoka `accuracy` 0.94 była złudna. Dodanie `class_weight='balanced'` znacząco poprawiło sytuację – `Recall` wzrósł do 0.55 (6 z 11 próbek wykrytych), `F1-score` do 0.27, choć kosztem większej liczby fałszywych alarmów. Oversampling metodą SMOTE utrzymał `Recall` 0.55, ale osiągnął najlepszy `F1-score` 0.29 dzięki wyższej precyzji (0.19). Undersampling również osiągnął `Recall` 0.55, ale najniższą precyzję 0.13, przez co `F1-score` spadł do 0.21.

Podsumowując: wszystkie techniki balansowania znacząco poprawiły wykrywalność rzadkiej klasy w porównaniu do modelu bazowego, a SMOTE zapewnił najlepszy kompromis między `Recall` a `Precision`.


| Model | F1-Score (dla klasy 1) | Recall (dla klasy 1) | Precision (dla klasy 1) |
| :--- | :---: | :---: | :---: |
| Bazowy | 0.13 | 0.09 | 0.25 |
| `class_weight` | 0.27 | **0.55** | 0.18 |
| **SMOTE** | **0.29** | **0.55** | **0.19** |
| Undersampling | 0.21 | **0.55** | 0.13 |